{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1hLZhBFAelH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7362bd9b-2bae-4bbb-dae4-82296294bc86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e6d4cdc1850>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import ast\n",
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gdown  # For downloading from Google Drive\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"preprocessed_yelp_data.csv\", delimiter=',')\n",
        "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)\n",
        "train_df.shape, test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqzPLcrdAq-0",
        "outputId": "66b3355b-252b-4029-87b0-77a750c072a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 2), (200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocabulary(texts:list, max_size:int=10000, min_freq:int=2):\n",
        "  \"\"\"\n",
        "  converts list of list of words store in texts to vocabulary dictionary\n",
        "  \"\"\"\n",
        "  word_count = collections.Counter()\n",
        "  for text in texts:\n",
        "      word_count.update(text)\n",
        "  print(\"No. of unique words (without any filters): \",len(word_count))\n",
        "  vocabulary = {\n",
        "      '<UKN>': 0,\n",
        "      '<PAD>': 1,\n",
        "  }\n",
        "  idx = 2\n",
        "  for word, count in word_count.items():\n",
        "    if count >= min_freq and len(vocabulary) <= max_size:\n",
        "      vocabulary[word] = idx\n",
        "      idx += 1\n",
        "  return vocabulary\n",
        "# conver string format to list of list of words\n",
        "train_texts = train_df['text'].tolist()\n",
        "train_texts = [ast.literal_eval(text) for text in train_texts]\n",
        "test_texts = test_df['text'].tolist()\n",
        "test_texts = [ast.literal_eval(text) for text in test_texts]\n",
        "vocab = build_vocabulary(train_texts)\n",
        "print(\"len of vocabulary: \", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONEj5aAbLzJf",
        "outputId": "8424372f-cb57-4bfe-d485-8ade99aa5494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of unique words (without any filters):  1826\n",
            "len of vocabulary:  762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_numeric = np.empty((len(train_texts),), dtype=object)\n",
        "test_numeric = np.empty((len(test_texts),), dtype=object)\n",
        "\n",
        "def numericalize_text(word_list:list, vocab:dict):\n",
        "  return np.array([vocab.get(word, 0) for word in word_list])\n",
        "\n",
        "\n",
        "###################\n",
        "# Adding one as padding\n",
        "###################\n",
        "for i,words in enumerate(train_texts):\n",
        "  temp_res = np.array(numericalize_text(words, vocab))\n",
        "  if len(temp_res) < 100:\n",
        "    train_numeric[i] = np.concatenate((temp_res, np.ones(100-len(temp_res))))\n",
        "  else:\n",
        "    train_numeric[i] = temp_res\n",
        "\n",
        "for i, words in enumerate(test_texts):\n",
        "  temp_res = np.array(numericalize_text(words, vocab))\n",
        "  if len(temp_res) < 100:\n",
        "    test_numeric[i] = np.concatenate((temp_res, np.ones(100-len(temp_res))))\n",
        "  else:\n",
        "    test_numeric[i] = temp_res\n"
      ],
      "metadata": {
        "id": "JQjN0Brc-9DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tensor = torch.tensor(np.array([torch.tensor(sub_arr) for sub_arr in train_numeric]))\n",
        "test_tensor = torch.tensor(np.array([torch.tensor(sub_arr) for sub_arr in test_numeric]))\n",
        "\n",
        "# trainloader = DataLoader(train_tensor, batch_size = 32, shuffle = True)\n",
        "# testloader = DataLoader(test_tensor, batch_size = 32, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "PGXSL8WWMq-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor(np.array([torch.tensor(sub_arr) for sub_arr in train_numeric]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsyAB0RkjtNX",
        "outputId": "4576c986-2e70-46ee-9b9c-46f317338af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2.,   3.,   4.,  ...,   1.,   1.,   1.],\n",
              "        [  7.,   8.,   9.,  ...,   1.,   1.,   1.],\n",
              "        [ 12.,  13.,  14.,  ...,   1.,   1.,   1.],\n",
              "        ...,\n",
              "        [ 19.,  77., 106.,  ...,   1.,   1.,   1.],\n",
              "        [ 71.,   4.,  29.,  ...,   1.,   1.,   1.],\n",
              "        [364., 542., 147.,  ...,   1.,   1.,   1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the embedding layer with a vocabulary size of 10,000 and embedding dimension of 100\n",
        "embedding_layer = nn.Embedding(101, 100)\n",
        "\n",
        "# Example input: a sequence of word indices\n",
        "word_indices = torch.tensor([1, 4, 2, 8, 99, 100])  # Example indices\n",
        "\n",
        "# Get the corresponding embeddings for these indices\n",
        "embeddings = embedding_layer(word_indices)\n",
        "\n",
        "print(\"Word indices:\", word_indices)\n",
        "print(\"Embeddings:\", embeddings)\n",
        "print(\"Shape of embeddings:\", embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGgbMktVwgPV",
        "outputId": "a1efeff3-238f-4047-d54d-63d41c91bc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word indices: tensor([  1,   4,   2,   8,  99, 100])\n",
            "Embeddings: tensor([[ 6.4076e-01,  5.8325e-01,  1.0669e+00, -4.5015e-01, -1.8527e-01,\n",
            "          7.5276e-01,  4.0476e-01,  1.7847e-01,  2.6491e-01,  1.2732e+00,\n",
            "         -1.3109e-03, -3.0360e-01, -1.4570e+00, -1.0234e-01, -5.9915e-01,\n",
            "          4.7706e-01,  7.2618e-01,  9.1152e-02, -3.8907e-01,  5.2792e-01,\n",
            "         -1.2685e-02,  2.4084e-01,  1.3254e-01,  7.6424e-01,  1.0950e+00,\n",
            "          3.3989e-01,  7.1997e-01,  4.1141e-01,  1.9312e+00,  1.0119e+00,\n",
            "         -1.4364e+00, -1.1299e+00, -1.3603e-01,  1.6354e+00,  6.5474e-01,\n",
            "          5.7600e-01,  1.1415e+00,  1.8565e-02, -1.8058e+00,  9.2543e-01,\n",
            "         -3.7534e-01,  1.0331e+00, -6.8665e-01,  6.3681e-01, -9.7267e-01,\n",
            "          9.5846e-01,  1.6192e+00,  1.4506e+00,  2.6948e-01, -2.1038e-01,\n",
            "         -7.3280e-01,  1.0430e-01,  3.4875e-01,  9.6759e-01, -4.6569e-01,\n",
            "          1.6048e+00, -2.4801e+00, -4.1754e-01, -1.1955e+00,  8.1234e-01,\n",
            "         -1.9006e+00,  2.2858e-01,  2.4859e-02, -3.4595e-01,  2.8683e-01,\n",
            "         -7.3084e-01,  1.7482e-01, -1.0939e+00, -1.6022e+00,  1.3529e+00,\n",
            "          1.2888e+00,  5.2295e-02, -1.5469e+00,  7.5671e-01,  7.7552e-01,\n",
            "          2.0265e+00,  3.5818e-02,  1.2059e-01, -8.0566e-01, -2.0758e-01,\n",
            "         -9.3195e-01, -1.5910e+00, -1.1360e+00, -5.2260e-01, -5.1877e-01,\n",
            "         -1.5013e+00, -1.9267e+00,  1.2785e-01,  1.0229e+00, -5.5580e-01,\n",
            "          7.0427e-01,  7.0988e-01,  1.7744e+00, -9.2155e-01,  9.6245e-01,\n",
            "         -3.3702e-01, -1.1753e+00,  3.5806e-01,  4.7877e-01,  1.3537e+00],\n",
            "        [ 2.4700e-02, -1.0641e+00, -7.6019e-01, -4.0751e-01,  9.6236e-01,\n",
            "         -1.4264e-01,  1.5271e-01, -3.8802e-02,  9.4461e-01, -1.5824e+00,\n",
            "          9.8713e-01,  1.1457e+00, -1.4181e-01, -2.7634e-01, -1.9321e-01,\n",
            "          7.7678e-01,  6.8388e-01, -1.3246e+00, -5.1608e-01,  6.0018e-01,\n",
            "         -4.7022e-01, -6.0864e-01, -4.6192e-02, -1.6457e+00, -4.8333e-01,\n",
            "         -7.4029e-01,  3.1428e-01,  1.4156e-01,  1.0348e+00, -6.2644e-01,\n",
            "         -5.1509e-01,  6.9029e-01, -4.9400e-01,  1.1366e+00, -4.6184e-01,\n",
            "          1.4200e+00,  8.4852e-01, -4.7891e-02,  6.6856e-01,  1.0430e+00,\n",
            "          6.8990e-01, -1.3129e+00,  3.7804e-02, -1.1702e+00, -1.0319e-01,\n",
            "          1.1895e+00,  7.6069e-01, -7.4630e-01, -1.3839e+00,  4.8687e-01,\n",
            "         -1.0020e+00,  3.2949e-02, -4.2920e-01, -9.8180e-01, -6.4206e-01,\n",
            "          8.2659e-01,  1.5914e+00, -1.2081e-01, -4.8302e-01,  1.1330e-01,\n",
            "          7.7151e-02, -9.2281e-01, -1.2620e+00,  1.0861e+00,  1.0966e+00,\n",
            "         -6.8369e-01,  6.6043e-02, -7.7380e-04,  1.6206e-01,  1.1960e+00,\n",
            "         -1.3062e+00, -1.4040e+00, -1.0597e+00,  3.0573e-01,  4.1506e-01,\n",
            "         -7.1741e-01,  2.8340e+00,  1.9535e+00,  2.0487e+00, -1.0880e+00,\n",
            "          1.6217e+00,  8.5127e-01, -4.0047e-01, -6.0883e-01, -5.0810e-01,\n",
            "         -6.1849e-01, -1.6470e+00, -1.0362e+00, -4.5031e-01, -7.2966e-02,\n",
            "         -5.4795e-01, -1.1426e+00, -4.4875e-01, -3.0454e-02,  3.8303e-01,\n",
            "         -4.4770e-02,  1.1799e+00, -3.3143e-01,  6.4950e-01,  9.4959e-02],\n",
            "        [ 5.2606e-01,  2.1120e+00, -5.2076e-01, -9.3201e-01,  1.8516e-01,\n",
            "          1.0687e+00,  1.3065e+00,  4.5983e-01, -8.1463e-01, -1.0212e+00,\n",
            "         -4.9492e-01, -5.9225e-01,  1.5432e-01,  4.4077e-01, -1.4829e-01,\n",
            "         -2.3184e+00, -3.9800e-01,  1.0805e+00, -1.7809e+00,  1.5080e+00,\n",
            "          3.0943e-01, -5.0031e-01,  1.0350e+00,  1.6896e+00, -4.5051e-03,\n",
            "          1.6668e+00,  1.5392e-01, -1.0603e+00, -5.7266e-01,  8.3568e-02,\n",
            "          3.9991e-01,  1.9892e+00, -7.1988e-02, -9.0609e-01, -2.0487e+00,\n",
            "         -1.0811e+00,  1.7623e-02,  7.8226e-02,  1.9316e-01,  4.0967e-01,\n",
            "         -9.2913e-01,  2.7619e-01, -5.3888e-01,  4.6258e-01, -8.7189e-01,\n",
            "         -2.7118e-02, -3.5325e-01,  1.4639e+00,  1.2554e+00, -7.1496e-01,\n",
            "          8.5392e-01,  5.1299e-01,  5.3973e-01,  5.6551e-01,  5.0579e-01,\n",
            "          2.2245e-01, -6.8548e-01,  5.6356e-01, -1.5072e+00, -1.6107e+00,\n",
            "         -1.4790e+00,  4.3227e-01, -1.2503e-01,  7.8212e-01, -1.5988e+00,\n",
            "         -1.0913e-01,  7.1520e-01,  3.9139e-02,  1.3059e+00,  2.4659e-01,\n",
            "         -1.9776e+00,  1.7896e-02, -1.3793e+00,  6.2580e-01, -2.5850e+00,\n",
            "         -2.4000e-02, -1.2219e-01, -7.4700e-01,  1.7093e+00,  5.7923e-02,\n",
            "          1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01,  4.1459e-01,\n",
            "          1.1566e+00,  2.6905e-01, -3.6629e-02,  9.7329e-01, -1.0151e+00,\n",
            "         -5.4192e-01, -4.4102e-01, -3.1362e-01, -1.2925e-01, -7.1496e-01,\n",
            "         -4.7562e-02,  2.0207e+00,  2.5392e-01,  9.3644e-01,  7.1224e-01],\n",
            "        [ 9.2130e-01,  5.2824e-01, -8.2284e-03, -1.4493e+00, -6.0518e-01,\n",
            "         -1.7925e-01,  1.9956e-01, -1.2462e+00, -4.1460e-01,  1.4559e+00,\n",
            "          3.3165e-01, -1.0001e+00, -6.9195e-01, -4.7199e-01, -1.2894e+00,\n",
            "          1.0763e+00, -1.0667e+00, -1.9893e+00,  2.9731e-01,  4.3446e-01,\n",
            "          3.3933e-03, -1.0240e+00,  2.2405e-01, -7.5548e-01,  1.3676e+00,\n",
            "         -3.1974e-01, -9.1309e-01,  1.9192e+00, -1.6515e+00,  2.1477e+00,\n",
            "         -6.6041e-01,  1.1353e-01, -2.2057e-01,  7.1181e-01,  3.4159e-01,\n",
            "          1.5886e+00, -3.4888e-01, -4.5792e-01, -1.2322e+00, -5.9808e-01,\n",
            "         -2.8155e-01,  5.2819e-02,  4.2498e-01,  4.8258e-01,  4.8813e-01,\n",
            "          1.0082e+00, -5.9500e-01,  3.9263e-01,  8.2297e-01, -8.8603e-01,\n",
            "          1.4801e+00,  8.3915e-01, -2.0005e-01,  9.9495e-01,  7.2019e-01,\n",
            "         -1.3413e-01, -1.4068e+00, -2.3610e+00, -2.9049e-01, -1.3346e-01,\n",
            "         -1.5693e-01,  1.1383e+00, -2.5052e-01,  1.6705e+00, -5.4527e-01,\n",
            "         -2.1582e+00, -1.6608e+00, -6.6374e-01,  3.6579e-01, -3.9920e-01,\n",
            "          4.9674e-01, -2.3692e+00, -5.6147e-01, -5.9491e-01,  1.2687e+00,\n",
            "          1.2904e+00, -1.1756e+00, -7.8323e-02, -9.7058e-01,  1.4724e+00,\n",
            "          1.4109e+00, -1.3144e+00, -1.3162e+00, -1.2524e+00, -1.5844e+00,\n",
            "         -2.5447e+00,  1.3719e+00, -5.3795e-01,  7.3784e-01, -8.5053e-01,\n",
            "          3.6101e-02,  1.3407e+00,  9.2000e-01, -3.7876e-01, -1.5598e+00,\n",
            "         -8.0095e-01, -7.1111e-01, -3.8667e-01,  9.5783e-01, -8.2253e-01],\n",
            "        [ 9.3022e-01,  1.6466e+00,  1.3799e+00,  7.3825e-01, -1.5669e+00,\n",
            "         -5.9329e-02, -1.1456e+00,  6.2637e-01, -1.3724e-01, -7.4541e-01,\n",
            "          8.6038e-01,  1.5647e+00,  1.3382e+00, -6.0992e-03,  3.9604e-02,\n",
            "         -1.8056e-01, -8.1566e-01,  5.6937e-01, -1.3829e+00,  1.0817e+00,\n",
            "         -1.4839e+00, -1.7180e+00, -2.4708e-01,  7.4986e-01, -1.1685e+00,\n",
            "          4.0370e-01,  1.2923e+00, -8.6289e-01, -4.4038e-01,  1.1935e+00,\n",
            "          6.9936e-01,  1.3272e+00, -1.1171e+00,  7.0059e-02,  6.2814e-01,\n",
            "          1.8614e+00, -1.9777e-01,  1.8756e+00,  8.3853e-01, -1.4788e-01,\n",
            "         -1.3152e+00, -2.1194e-02, -1.3232e+00, -3.4254e-01,  1.2097e-01,\n",
            "          1.8160e+00,  3.5290e-01,  7.1534e-01, -4.8528e-01,  1.5847e+00,\n",
            "          1.5597e+00, -7.6857e-01,  5.4263e-01, -1.1759e+00,  1.5627e+00,\n",
            "         -1.4737e+00,  2.6301e-01,  4.4040e-04,  1.1922e-01, -1.2865e+00,\n",
            "          1.2466e+00, -1.3868e+00,  4.2800e-01,  8.4444e-01, -6.9548e-01,\n",
            "          1.7099e+00, -3.0377e-01,  6.8366e-01,  8.1244e-01, -2.3456e+00,\n",
            "          6.3711e-01,  9.7394e-01, -2.8066e-01,  7.4962e-01,  7.2969e-01,\n",
            "          7.5849e-02,  2.5085e+00,  1.2586e+00,  2.2998e-01,  1.2981e-01,\n",
            "         -9.6726e-01,  4.2772e-01, -1.2849e+00,  2.9293e-01, -1.0284e+00,\n",
            "         -6.8625e-01,  1.0597e-01, -1.4316e-01,  5.8982e-01,  1.6718e-01,\n",
            "          1.3842e+00, -1.2705e+00, -4.1871e-01, -1.6622e+00, -5.1696e-02,\n",
            "         -7.7951e-02, -1.0599e+00,  8.2270e-01, -8.5460e-01,  7.9412e-01],\n",
            "        [-1.1723e+00,  4.0684e-01, -6.1652e-01, -6.1367e-01,  1.0867e+00,\n",
            "          6.1683e-01,  2.8539e-01,  1.3248e+00, -1.2534e+00, -1.0481e-01,\n",
            "         -2.5498e-01, -2.9671e-01, -1.3069e+00,  9.6966e-01, -5.0373e-02,\n",
            "          2.7439e+00,  1.1964e+00, -6.1898e-01, -3.7927e-01,  2.0629e+00,\n",
            "         -2.9981e-01, -5.3221e-01,  5.6230e-01, -2.1050e+00,  3.8068e-01,\n",
            "          3.3977e-02, -4.7510e-01, -2.5976e-01,  9.0976e-01,  8.7123e-01,\n",
            "          2.0274e+00, -2.1792e+00, -1.4525e-01,  8.5682e-01, -1.0604e+00,\n",
            "         -4.7393e-01,  8.3548e-01,  5.5231e-01,  9.8776e-01,  2.4725e-01,\n",
            "         -1.3898e+00,  7.8795e-01,  2.6193e-01,  3.2392e-01, -6.5642e-03,\n",
            "         -6.6077e-01,  1.0100e+00,  1.5781e+00,  3.6729e-01,  9.2778e-01,\n",
            "          3.3918e-01, -2.6325e-01, -8.0795e-01,  5.9070e-02, -4.6642e-01,\n",
            "         -8.8633e-01, -3.5493e-01, -2.8071e-01,  1.1867e-01, -1.6083e+00,\n",
            "         -5.3039e-02, -7.5456e-01,  1.1250e+00,  2.1489e-01,  1.1615e+00,\n",
            "          1.4790e+00, -2.4605e-01,  7.6225e-01, -1.8944e-01,  6.2148e-02,\n",
            "          2.6847e-01,  6.0526e-01,  1.2565e-02, -1.9676e-01,  1.6451e+00,\n",
            "          1.3394e+00,  1.2698e+00, -4.5756e-01,  6.3750e-01,  3.4380e-01,\n",
            "         -4.4698e-01, -7.3381e-01,  1.2820e-01, -1.0222e-01, -5.6402e-01,\n",
            "         -1.4401e-01, -5.0875e-01,  1.4537e+00,  1.2024e+00,  7.5886e-01,\n",
            "          9.7266e-01,  1.1990e+00, -1.1790e+00, -5.8466e-01, -8.6171e-02,\n",
            "          1.6757e+00,  4.3723e-01, -5.6639e-02, -1.3556e+00,  9.9083e-01]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Shape of embeddings: torch.Size([6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's create the RNNModel class with the specified layers and forward pass.\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, num_layers, output_size):\n",
        "\n",
        "        torch.manual_seed(42)\n",
        "        # Call the parent class's initialization method\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Initialize the embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "\n",
        "        # Initialize the RNN layer with specified parameters\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Initialize the linear layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through the embedding layer\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Pass the embeddings through the RNN layer\n",
        "        # `output` contains all time steps, `hidden` contains the last hidden state\n",
        "        output, hidden = self.rnn(embedded)\n",
        "\n",
        "        # Use the last hidden state to produce the final output\n",
        "        # We use hidden.squeeze(0) to remove unnecessary dimensions for linear layer\n",
        "        final_output = self.fc(hidden[-1, :, :])\n",
        "\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "Nzhb-VX9yjEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvHOHp3U3LVJ",
        "outputId": "b1a4395f-13ef-4493-bf93-18fda20bc971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "762"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with the given parameters\n",
        "input_size = 762  # Example vocabulary size\n",
        "embedding_dim = 100\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "\n",
        "model = RNNModel(input_size, embedding_dim, hidden_size, num_layers, output_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "CQxR4wLryn2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "total_params\n",
        "\n",
        "train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh4WYuq3zJNS",
        "outputId": "1192f9a2-4e25-422a-9338-38613bb542ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([800, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total number of parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Total number of parameters in the model:\", total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU1j1HVI3tKF",
        "outputId": "3e0abd2e-3b8b-42bc-d54b-ded6a6a33d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model: 299689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss with logits\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001"
      ],
      "metadata": {
        "id": "fpgrc6MK1ddP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArshisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, size, data, labels):\n",
        "        self.size = size\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "\n",
        "# tensors = [torch.tensor([x], dtype=torch.float32) for x in train_df['label']]\n",
        "\n",
        "# train_label = torch.stack(tensors)  # Stacks tensors along a new dimension\n",
        "\n",
        "# label_train = np.array(train_df['label'])\n",
        "\n",
        "train_dataset = ArshisDataset(800, train_tensor.long(), torch.tensor(train_df['label'].values, dtype=torch.float64))\n",
        "test_dataset = ArshisDataset(200, test_tensor.long(), torch.tensor(test_df['label'].values, dtype=torch.float64))\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unOBUXu22i4H",
        "outputId": "3526ea65-bc8e-4c2b-f3be-07e38d2c8d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7e6c5669ac20>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in test_loader:\n",
        "  print(labels)\n",
        "  print(len(inputs[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70IjRUNWL1Lx",
        "outputId": "2092d5d5-7244-4072-eb89-732e34d3f7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
            "        0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
            "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
            "        0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
            "        0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
            "        0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
            "       dtype=torch.float64)\n",
            "100\n",
            "tensor([1., 1., 0., 1., 1., 0., 0., 1.], dtype=torch.float64)\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9gsXaeCD0hoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, data_loader, criterion, optimizer, epochs=2):\n",
        "    \"\"\"\n",
        "    Trains the given model using the specified data loader, loss function (criterion),\n",
        "    and optimizer. The training process includes forward propagation, loss calculation,\n",
        "    backpropagation, and parameter updates. The function trains for a given number of epochs.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The PyTorch model to be trained.\n",
        "    - data_loader (DataLoader): A PyTorch DataLoader providing the training data.\n",
        "    - criterion (nn.Module): The loss function used to compute the loss.\n",
        "    - optimizer (torch.optim.Optimizer): The optimizer used to update model parameters.\n",
        "    - epochs (int): The number of epochs to train the model for.\n",
        "\n",
        "    During each epoch, the function iterates over the data loader, performs a forward pass\n",
        "    to compute model outputs, calculates the loss, and performs backpropagation to update\n",
        "    model parameters. At the end of each epoch, it prints the average loss.\n",
        "    \"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        model.train()  # Set the model to training mode\n",
        "\n",
        "        for inputs, labels in data_loader:\n",
        "            optimizer.zero_grad()  # Clear gradients from the previous step\n",
        "\n",
        "            # Forward pass to get predictions\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs.squeeze(), labels)  # `squeeze` is used to ensure correct dimensions\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()  # Update model parameters\n",
        "\n",
        "            total_loss += loss.item()  # Accumulate total loss\n",
        "\n",
        "        # Print the average loss for this epoch\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(data_loader):.4f}\")\n",
        "\n",
        "# Example usage: Train the model for 2 epochs\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avasNpgSz61u",
        "outputId": "10607d7a-9cb6-4663-98ad-37b26dabae37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Loss: 0.7063\n",
            "Epoch 2/2, Loss: 0.6987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmXASuqcLzlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Function to evaluate a model's performance\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    \"\"\"\n",
        "    Evaluates the given model on the provided data loader using the specified criterion.\n",
        "    Computes and returns the average loss and accuracy over the entire data loader.\n",
        "\n",
        "    Parameters:\n",
        "    - model (torch.nn.Module): The trained model to evaluate.\n",
        "    - data_loader (DataLoader): The DataLoader containing the test/validation data.\n",
        "    - criterion (torch.nn.Module): The loss function used to compute the loss.\n",
        "\n",
        "    Returns:\n",
        "    - average_loss (float): The average loss over the evaluation dataset.\n",
        "    - accuracy (float): The accuracy of the model on the evaluation dataset.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for inputs, labels in data_loader:\n",
        "            # Forward pass to compute predictions\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs.squeeze(), labels)  # `squeeze` if needed\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Compute accuracy\n",
        "            predicted = torch.round(torch.sigmoid(outputs.squeeze()))  # For binary classification\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # Calculate average loss and accuracy\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct / total  # Accuracy as a fraction\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "\n",
        "# Example: Evaluate the model\n",
        "average_loss, accuracy = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "print(f\"Average Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryj9Zt6WKsz2",
        "outputId": "e9c1df1f-247c-43ef-8570-a47444361548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Loss: 0.6913, Accuracy: 0.5200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_test = torch.rand(800, 10)  # Example data tensor with 800 samples, 10 features\n",
        "train_label_ = torch.rand(800)  # Example label tensor with 800 samples\n",
        "\n",
        "# train_dataset = ArshisDataset(train_tensor, train_label)\n",
        "train_label_\n",
        "\n"
      ],
      "metadata": {
        "id": "V7cKl3CzjynM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArshisDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        assert len(data) == len(labels), \"Data and labels must have the same length\"\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Ensure correct indexing\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "train_tensor = torch.rand(800, 10)  # Example data tensor with 800 samples, 10 features\n",
        "train_label = torch.rand(800)  # Example label tensor with 800 samples\n",
        "\n",
        "train_dataset = ArshisDataset(train_tensor, train_label)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Print the first batch\n",
        "for data, labels in train_loader:\n",
        "    print(\"Data:\", data)\n",
        "    print(\"Labels:\", labels)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCZSHZcZ969Y",
        "outputId": "2c6b2285-e759-45fa-bf88-53bc73b67142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: tensor([[0.0735, 0.4385, 0.5392, 0.3614, 0.2037, 0.8320, 0.4848, 0.4929, 0.7033,\n",
            "         0.5768],\n",
            "        [0.9705, 0.4782, 0.8531, 0.7704, 0.5869, 0.3167, 0.2523, 0.3324, 0.9485,\n",
            "         0.2181],\n",
            "        [0.8717, 0.7381, 0.0389, 0.7050, 0.8945, 0.5052, 0.7315, 0.8322, 0.4007,\n",
            "         0.6886],\n",
            "        [0.4616, 0.0584, 0.9420, 0.0287, 0.9097, 0.5480, 0.1629, 0.1288, 0.9505,\n",
            "         0.6913],\n",
            "        [0.6536, 0.1348, 0.0302, 0.4239, 0.0759, 0.7367, 0.3147, 0.3615, 0.3551,\n",
            "         0.0914],\n",
            "        [0.2778, 0.1824, 0.0697, 0.0777, 0.9462, 0.3664, 0.9064, 0.8448, 0.9228,\n",
            "         0.3518],\n",
            "        [0.4971, 0.1723, 0.3808, 0.9025, 0.4658, 0.5968, 0.8892, 0.4174, 0.1067,\n",
            "         0.8236],\n",
            "        [0.2486, 0.1902, 0.4287, 0.7010, 0.5473, 0.6647, 0.9828, 0.5185, 0.1332,\n",
            "         0.6606],\n",
            "        [0.7847, 0.0241, 0.8566, 0.8331, 0.6656, 0.3612, 0.1110, 0.9081, 0.7706,\n",
            "         0.0075],\n",
            "        [0.3872, 0.6572, 0.2446, 0.6970, 0.4065, 0.7295, 0.4252, 0.1582, 0.6111,\n",
            "         0.8187],\n",
            "        [0.6595, 0.4690, 0.5522, 0.8826, 0.7429, 0.6646, 0.6346, 0.9020, 0.9864,\n",
            "         0.1807],\n",
            "        [0.2148, 0.0641, 0.2061, 0.5597, 0.2276, 0.2523, 0.0534, 0.0612, 0.8987,\n",
            "         0.8404],\n",
            "        [0.4480, 0.9164, 0.1944, 0.5501, 0.9740, 0.5199, 0.1955, 0.7268, 0.6608,\n",
            "         0.0398],\n",
            "        [0.3698, 0.2290, 0.9807, 0.1967, 0.5223, 0.7132, 0.2899, 0.6885, 0.4901,\n",
            "         0.8804],\n",
            "        [0.0636, 0.0401, 0.4476, 0.2209, 0.9200, 0.5998, 0.3793, 0.7564, 0.8399,\n",
            "         0.4945],\n",
            "        [0.4117, 0.6801, 0.5175, 0.2842, 0.5692, 0.2113, 0.4363, 0.3418, 0.1042,\n",
            "         0.1944],\n",
            "        [0.0520, 0.0886, 0.6240, 0.6680, 0.5759, 0.8940, 0.2249, 0.1578, 0.5486,\n",
            "         0.8812],\n",
            "        [0.8563, 0.9109, 0.7985, 0.2812, 0.9044, 0.6268, 0.8359, 0.7247, 0.2469,\n",
            "         0.4599],\n",
            "        [0.2281, 0.4800, 0.1691, 0.2068, 0.1781, 0.1328, 0.6025, 0.6770, 0.3561,\n",
            "         0.4135],\n",
            "        [0.0137, 0.4915, 0.5781, 0.1016, 0.9103, 0.7747, 0.7344, 0.6963, 0.9548,\n",
            "         0.0147],\n",
            "        [0.3444, 0.6239, 0.2105, 0.8757, 0.2727, 0.6964, 0.7897, 0.6898, 0.1944,\n",
            "         0.9939],\n",
            "        [0.7647, 0.0025, 0.9400, 0.6055, 0.7223, 0.0016, 0.6781, 0.6762, 0.4536,\n",
            "         0.9801],\n",
            "        [0.4044, 0.5962, 0.9232, 0.7143, 0.4546, 0.1789, 0.6903, 0.4822, 0.9377,\n",
            "         0.8966],\n",
            "        [0.2727, 0.0718, 0.3641, 0.0428, 0.6158, 0.7349, 0.1408, 0.1236, 0.9970,\n",
            "         0.3530],\n",
            "        [0.5875, 0.3931, 0.7838, 0.2883, 0.1033, 0.8404, 0.6225, 0.0544, 0.2744,\n",
            "         0.4629],\n",
            "        [0.6448, 0.5190, 0.1959, 0.6900, 0.5123, 0.7678, 0.1694, 0.4330, 0.4316,\n",
            "         0.6586],\n",
            "        [0.3778, 0.9574, 0.1016, 0.2325, 0.0594, 0.0039, 0.9742, 0.2928, 0.6657,\n",
            "         0.3792],\n",
            "        [0.4037, 0.6709, 0.9507, 0.7370, 0.0309, 0.9063, 0.7761, 0.3066, 0.8219,\n",
            "         0.9149],\n",
            "        [0.0754, 0.3934, 0.9983, 0.4389, 0.6935, 0.3464, 0.8689, 0.1029, 0.1673,\n",
            "         0.1503],\n",
            "        [0.1321, 0.5616, 0.3765, 0.5915, 0.0370, 0.9509, 0.3601, 0.6855, 0.5133,\n",
            "         0.0213],\n",
            "        [0.7761, 0.7666, 0.1037, 0.5956, 0.7478, 0.7073, 0.0021, 0.2378, 0.0587,\n",
            "         0.1428],\n",
            "        [0.6795, 0.0114, 0.8937, 0.3145, 0.6988, 0.1032, 0.5902, 0.7663, 0.5225,\n",
            "         0.4352]])\n",
            "Labels: tensor([0.2315, 0.3998, 0.1204, 0.1244, 0.6233, 0.3006, 0.6498, 0.5720, 0.3838,\n",
            "        0.7925, 0.5295, 0.0243, 0.5654, 0.6638, 0.8679, 0.6738, 0.9613, 0.6586,\n",
            "        0.4511, 0.4886, 0.4710, 0.7295, 0.1668, 0.3115, 0.7741, 0.9807, 0.4048,\n",
            "        0.3430, 0.0561, 0.2463, 0.8287, 0.8764])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor = torch.tensor([[[1], [2], [3]], [[4], [5], [6]]])\n",
        "squeezed_tensor = tensor.squeeze(1)  # Removes singleton dimensions\n"
      ],
      "metadata": {
        "id": "LyuV1c8ICVcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU-nzws4Olft",
        "outputId": "2e52f63c-5936-4c82-f8a6-3db57ac096f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1],\n",
              "         [2],\n",
              "         [3]],\n",
              "\n",
              "        [[4],\n",
              "         [5],\n",
              "         [6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnCZ05p-Owcn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}